{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCYUNZfmuSEY",
        "outputId": "2e621f51-e2c9-47bd-bca8-4d31cc1608be"
      },
      "outputs": [],
      "source": [
        "# !pip install imblearn\n",
        "# !pip install numpy\n",
        "# !pip install pandas\n",
        "# !pip install tqdm\n",
        "# !pip install sklearn\n",
        "# !pip install torch\n",
        "# !pip install flwr\n",
        "# !pip install -U \"flwr[simulation]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameters to match paper\n",
        "dataset_number = 5  # non-IID clients (devices)\n",
        "K = 6  # clients\n",
        "local_epochs = 5  # E=5\n",
        "T = 10  # Communication rounds\n",
        "batch_size = 256\n",
        "latent_dim = 16  # As per paper (originally 10 in code, updated)\n",
        "lr = 1e-4\n",
        "beta_momentum = 0.9\n",
        "delta_sep = 2.0  # δ=2.0\n",
        "lambda_proj = 0.1  # λ=0.1\n",
        "min_sigma = 0.1  # Variance clipping\n",
        "num_classes = 2\n",
        "\n",
        "\n",
        "def get_ctvae_acc(dataset_number):\n",
        "    acc = {1: 93.0, 2: 95.0, 3: 93.9, 4: 91.8, 5: 93.1, 6: 94.5, 7: 96.6, 8: 100.0, 9: 98.9}\n",
        "    return acc[dataset_number]\n",
        "\n",
        "\n",
        "def get_ctvae_f1(dataset_number):\n",
        "    f1 = {1: 90.9, 2: 93.5, 3: 92.2, 4: 89.5, 5: 91.1, 6: 93.3, 7: 95.5, 8: 100.0, 9: 99.0}\n",
        "    return f1[dataset_number]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cpu\n"
          ]
        }
      ],
      "source": [
        "import flwr as fl\n",
        "from flwr.server.strategy import Strategy\n",
        "from flwr.common import (\n",
        "    Parameters,\n",
        "    FitRes,\n",
        "    EvaluateRes,\n",
        "    NDArrays,\n",
        "    ndarrays_to_parameters,\n",
        "    parameters_to_ndarrays,\n",
        ")\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "from typing import List, Optional, Tuple, Dict\n",
        "import json\n",
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
        "from imblearn.combine import SMOTETomek\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import time\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 50)\n",
        "        self.fc_mu = nn.Linear(50, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(50, latent_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.relu(self.fc1(x))\n",
        "        mu = self.fc_mu(h)\n",
        "        logvar = self.fc_logvar(h)\n",
        "        return mu, logvar\n",
        "\n",
        "class Hermaphrodite(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Hermaphrodite, self).__init__()\n",
        "        self.fc1 = nn.Linear(latent_dim, 64)  # Updated to 64 as per paper\n",
        "        self.fc_out = nn.Linear(64, latent_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, z):\n",
        "        h = self.relu(self.fc1(z))\n",
        "        z_hat = self.fc_out(h)\n",
        "        return z_hat\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(latent_dim, 50)\n",
        "        self.fc_out = nn.Linear(50, input_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, z):\n",
        "        h = self.relu(self.fc1(z))\n",
        "        recon = self.sigmoid(self.fc_out(h))\n",
        "        return recon\n",
        "\n",
        "class CTVAE(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim, num_classes=2):\n",
        "        super(CTVAE, self).__init__()\n",
        "        self.encoder = Encoder(input_dim, latent_dim)\n",
        "        self.hermaphrodite = Hermaphrodite(latent_dim)\n",
        "        self.decoder = Decoder(input_dim, latent_dim)\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.register_buffer('mu_c', torch.zeros(num_classes, latent_dim))\n",
        "        self.register_buffer('sigma_c', torch.ones(num_classes, latent_dim))\n",
        "\n",
        "    def sampling(self, mu, logvar, y=None, constrained=False):\n",
        "        if constrained and y is not None:\n",
        "            eps = torch.randn_like(mu)\n",
        "            for i in range(mu.shape[0]):\n",
        "                c = y[i].item()\n",
        "                eps[i] = eps[i] * self.sigma_c[c] + self.mu_c[c]\n",
        "            return mu + torch.exp(0.5 * logvar) * eps\n",
        "        else:\n",
        "            eps = torch.randn_like(mu)\n",
        "            return mu + torch.exp(0.5 * logvar) * eps\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        mu, logvar = self.encoder(x)\n",
        "        z = self.sampling(mu, logvar, y, constrained=True if y is not None else False)\n",
        "        z_hat = self.hermaphrodite(z)\n",
        "        recon = self.decoder(z_hat)\n",
        "        return recon, mu, logvar, z_hat\n",
        "\n",
        "    def loss(self, recon, x, mu, logvar, z, z_hat, beta1=1.0, beta2=1.0):\n",
        "        recon_loss = nn.MSELoss(reduction='sum')(recon, x) / x.shape[0]\n",
        "        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1).mean()\n",
        "        z_hat_loss = nn.MSELoss()(z, z_hat)\n",
        "        total_loss = recon_loss + kl_loss + beta1 * z_hat_loss + beta2 * z_hat_loss\n",
        "        return total_loss, recon_loss, kl_loss, z_hat_loss\n",
        "\n",
        "def weights_init_glorot(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.zeros_(m.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data for a specific dataset_number (client)\n",
        "def load_data(dataset_number):\n",
        "    i = str(dataset_number)\n",
        "    benign = f\"dataset/{i}/{i}.benign.csv\"  # Assume datasets are downloaded\n",
        "    mirai = [f\"dataset/{i}/{i}.mirai.scan.csv\", f\"dataset/{i}/{i}.mirai.syn.csv\", f\"dataset/{i}/{i}.mirai.udp.csv\", f\"dataset/{i}/{i}.mirai.ack.csv\", f\"dataset/{i}/{i}.mirai.udpplain.csv\"]\n",
        "    gafgyt = [f\"dataset/{i}/{i}.gafgyt.combo.csv\", f\"dataset/{i}/{i}.gafgyt.junk.csv\", f\"dataset/{i}/{i}.gafgyt.scan.csv\", f\"dataset/{i}/{i}.gafgyt.tcp.csv\", f\"dataset/{i}/{i}.gafgyt.udp.csv\"]\n",
        "\n",
        "    benign_df = pd.read_csv(benign)\n",
        "    mirai_df = pd.concat([pd.read_csv(f) for f in mirai], ignore_index=True)\n",
        "    gafgyt_df = pd.concat([pd.read_csv(f) for f in gafgyt], ignore_index=True)\n",
        "\n",
        "    benign_train, benign_test = train_test_split(benign_df, test_size=0.3, random_state=42)\n",
        "    train_df = pd.concat([benign_train, mirai_df], ignore_index=True)\n",
        "    X_train = train_df.drop(columns=['label'], errors='ignore').values.astype(np.float32)\n",
        "    y_train = np.concatenate([np.zeros(len(benign_train)), np.ones(len(mirai_df))]).astype(np.int32)\n",
        "\n",
        "    test_df = pd.concat([benign_test, gafgyt_df], ignore_index=True)\n",
        "    X_test = test_df.drop(columns=['label'], errors='ignore').values.astype(np.float32)\n",
        "    y_test = np.concatenate([np.zeros(len(benign_test)), np.ones(len(gafgyt_df))]).astype(np.int32)\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    input_dim = X_train_scaled.shape[1]\n",
        "\n",
        "    X_train_torch = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
        "    y_train_torch = torch.tensor(y_train, dtype=torch.long).to(device)\n",
        "    X_test_torch = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
        "    y_test_torch = torch.tensor(y_test, dtype=torch.long).to(device)\n",
        "\n",
        "    return X_train_torch, y_train_torch, X_test_torch, y_test_torch, input_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pre-train global model on proxy data (merged small subsets)\n",
        "def pretrain_global():\n",
        "    X_train, y_train, _, _, _ = load_data(dataset_number)\n",
        "    \n",
        "    idx = np.random.choice(len(X_train), min(1000, len(X_train)), replace=False)\n",
        "    X_proxy = X_train[idx].cpu().numpy()\n",
        "    y_proxy = y_train[idx].cpu().numpy()\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    X_proxy = scaler.fit_transform(X_proxy)\n",
        "    input_dim = X_proxy.shape[1]\n",
        "\n",
        "    global_model = CTVAE(input_dim, latent_dim).to(device)\n",
        "    global_model.apply(weights_init_glorot)\n",
        "    optimizer = optim.Adam(global_model.parameters(), lr=lr)\n",
        "\n",
        "    dataset = TensorDataset(torch.tensor(X_proxy, dtype=torch.float32).to(device), torch.tensor(y_proxy, dtype=torch.long).to(device))\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    for epoch in range(100):  # E_server=100 as per paper\n",
        "        for batch_x, batch_y in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            recon, mu, logvar, z_hat = global_model(batch_x, batch_y)\n",
        "            z = global_model.sampling(mu, logvar, batch_y, True)\n",
        "            loss, _, _, _ = global_model.loss(recon, batch_x, mu, logvar, z, z_hat)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Calculate parameter counts for 62% reduction\n",
        "    total_params = sum(p.numel() for p in global_model.parameters())\n",
        "    selective_params = sum(p.numel() for p in global_model.hermaphrodite.parameters()) + sum(p.numel() for p in global_model.decoder.parameters()) + global_model.mu_c.numel() + global_model.sigma_c.numel()\n",
        "    reduction = (1 - selective_params / total_params) * 100\n",
        "    print(f\"Communication overhead reduction: {reduction:.2f}% (Selective: {selective_params}, Total: {total_params})\")\n",
        "\n",
        "    return global_model, input_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Flower Client\n",
        "class FCTVAEClient:\n",
        "    def __init__(self, cid, X_k, y_k, input_dim, latent_dim=16, lr=1e-4, epochs=5):\n",
        "        self.cid = cid\n",
        "        self.X_k = X_k.to(device)\n",
        "        self.y_k = y_k.to(device)\n",
        "        self.input_dim = input_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.epochs = epochs\n",
        "\n",
        "        # مدل محلی (فقط encoder رو آپدیت می‌کنیم — بقیه global هستن)\n",
        "        self.model = CTVAE(input_dim, latent_dim).to(device)\n",
        "        self.model.apply(weights_init_glorot)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "\n",
        "        self.dataset = TensorDataset(self.X_k, self.y_k)\n",
        "        self.dataloader = DataLoader(self.dataset, batch_size=256, shuffle=True)\n",
        "\n",
        "    def local_train(self, global_herm, global_decoder, global_mu_c, global_sigma_c):\n",
        "        # بارگذاری پارامترهای global (فقط herm, decoder, mu_c, sigma_c)\n",
        "        self.model.hermaphrodite.load_state_dict(global_herm)\n",
        "        self.model.decoder.load_state_dict(global_decoder)\n",
        "        self.model.mu_c.data = global_mu_c.clone()\n",
        "        self.model.sigma_c.data = global_sigma_c.clone()\n",
        "\n",
        "        self.model.train()\n",
        "        for epoch in range(self.epochs):\n",
        "            for batch_x, batch_y in self.dataloader:\n",
        "                self.optimizer.zero_grad()\n",
        "                recon, mu, logvar, z_hat = self.model(batch_x, batch_y)\n",
        "                z = self.model.sampling(mu, logvar, batch_y, constrained=True)\n",
        "                loss, _, _, _ = self.model.loss(recon, batch_x, mu, logvar, z, z_hat)\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "                self.optimizer.step()\n",
        "\n",
        "        # محاسبه delta (تفاوت با global)\n",
        "        delta_herm = {k: self.model.hermaphrodite.state_dict()[k] - global_herm[k] for k in global_herm}\n",
        "        delta_decoder = {k: self.model.decoder.state_dict()[k] - global_decoder[k] for k in global_decoder}\n",
        "        delta_mu_c = self.model.mu_c.data - global_mu_c\n",
        "        delta_sigma_c = self.model.sigma_c.data - global_sigma_c\n",
        "\n",
        "        return delta_herm, delta_decoder, delta_mu_c, delta_sigma_c, len(self.X_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CMGAStrategy(Strategy):\n",
        "    def __init__(self, global_model):\n",
        "        self.global_model = global_model\n",
        "\n",
        "    def initialize_parameters(self, client_manager):\n",
        "        return fl.common.ndarrays_to_parameters(\n",
        "            [val.cpu().numpy() for val in self.global_model.state_dict().values()]\n",
        "        )\n",
        "\n",
        "    def configure_fit(self, server_round: int, parameters: Parameters, client_manager):\n",
        "        \"\"\"انتخاب همه کلاینت‌ها در هر راند (برای شبیه‌سازی)\"\"\"\n",
        "        config = {}\n",
        "        fit_ins = fl.common.FitIns(parameters, config)\n",
        "        clients = client_manager.sample(num_clients=K, min_num_clients=K)\n",
        "        return [(client, fit_ins) for client in clients]\n",
        "\n",
        "    def aggregate_fit(self, server_round: int, results: List[Tuple[fl.server.client_proxy.ClientProxy, FitRes]], failures):\n",
        "        \"\"\"اینجا فقط پارامترهای selective رو جمع می‌کنیم (hermaphrodite + decoder + mu_c + sigma_c)\"\"\"\n",
        "        if not results:\n",
        "            return None, {}\n",
        "\n",
        "        # جمع‌آوری فقط پارامترهای selective از کلاینت‌ها\n",
        "        all_herm = []\n",
        "        all_decoder = []\n",
        "        all_mu_c = []\n",
        "        all_sigma_c = []\n",
        "\n",
        "        for _, fit_res in results:\n",
        "            params = fl.common.parameters_to_ndarrays(fit_res.parameters)\n",
        "            # فرض: کلاینت‌ها به ترتیب: hermaphrodite, decoder, mu_c, sigma_c می‌فرستند\n",
        "            herm_params = params[:len(self.global_model.hermaphrodite.state_dict())]\n",
        "            decoder_params = params[len(self.global_model.hermaphrodite.state_dict()):\n",
        "                                   len(self.global_model.hermaphrodite.state_dict()) + len(self.global_model.decoder.state_dict())]\n",
        "            mu_c = params[-2]\n",
        "            sigma_c = params[-1]\n",
        "\n",
        "            all_herm.extend(herm_params)\n",
        "            all_decoder.extend(decoder_params)\n",
        "            all_mu_c.append(mu_c)\n",
        "            all_sigma_c.append(sigma_c)\n",
        "\n",
        "        # میانگین ساده (یا می‌تونید momentum اضافه کنید)\n",
        "        new_herm = [np.mean([p[i] for p in all_herm], axis=0) for i in range(len(all_herm[0]))]\n",
        "        new_decoder = [np.mean([p[i] for p in all_decoder], axis=0) for i in range(len(all_decoder[0]))]\n",
        "        new_mu_c = np.mean(all_mu_c, axis=0)\n",
        "        new_sigma_c = np.mean(all_sigma_c, axis=0)\n",
        "\n",
        "        # آپدیت مدل جهانی\n",
        "        herm_sd = {k: torch.tensor(v) for k, v in zip(self.global_model.hermaphrodite.state_dict().keys(), new_herm)}\n",
        "        decoder_sd = {k: torch.tensor(v) for k, v in zip(self.global_model.decoder.state_dict().keys(), new_decoder)}\n",
        "        self.global_model.hermaphrodite.load_state_dict(herm_sd)\n",
        "        self.global_model.decoder.load_state_dict(decoder_sd)\n",
        "        self.global_model.mu_c.data = torch.tensor(new_mu_c).to(device)\n",
        "        self.global_model.sigma_c.data = torch.tensor(new_sigma_c).to(device)\n",
        "\n",
        "        # برگرداندن پارامترهای جدید (فقط selective)\n",
        "        new_params = new_herm + new_decoder + [new_mu_c, new_sigma_c]\n",
        "        return fl.common.ndarrays_to_parameters(new_params), {}\n",
        "\n",
        "    def configure_evaluate(self, server_round: int, parameters: Parameters, client_manager):\n",
        "        return []\n",
        "\n",
        "    def aggregate_evaluate(self, server_round: int, results, failures):\n",
        "        return None, {}\n",
        "\n",
        "    def evaluate(self, server_round: int, parameters: Parameters):\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "STARTING F-CTVAE FEDERATED SIMULATION\n",
            "Dataset: IoT-5 | Clients: 6 | Epochs: 5 | Rounds: 10\n",
            "==================================================\n",
            "\n",
            "Communication overhead reduction: 45.27% (Selective: 8907, Total: 16275)\n",
            "\n",
            "--- Round 1/10 ---\n",
            "Round 1 completed. Updated global model.\n",
            "\n",
            "--- Round 2/10 ---\n",
            "Round 2 completed. Updated global model.\n",
            "\n",
            "--- Round 3/10 ---\n",
            "Round 3 completed. Updated global model.\n",
            "\n",
            "--- Round 4/10 ---\n",
            "Round 4 completed. Updated global model.\n",
            "\n",
            "--- Round 5/10 ---\n",
            "Round 5 completed. Updated global model.\n",
            "\n",
            "--- Round 6/10 ---\n",
            "Round 6 completed. Updated global model.\n",
            "\n",
            "--- Round 7/10 ---\n",
            "Round 7 completed. Updated global model.\n",
            "\n",
            "--- Round 8/10 ---\n",
            "Round 8 completed. Updated global model.\n",
            "\n",
            "--- Round 9/10 ---\n",
            "Round 9 completed. Updated global model.\n",
            "\n",
            "--- Round 10/10 ---\n",
            "Round 10 completed. Updated global model.\n",
            "\n",
            "Training Finished!\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"STARTING F-CTVAE FEDERATED SIMULATION\")\n",
        "print(f\"Dataset: IoT-{dataset_number} | Clients: {K} | Epochs: {local_epochs} | Rounds: {T}\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "global_model, input_dim = pretrain_global()\n",
        "client_data = load_data(dataset_number)\n",
        "X_train, y_train, X_test, y_test, input_dim = client_data\n",
        "client = FCTVAEClient(cid=\"0\", X_k=X_train, y_k=y_train, input_dim=input_dim)\n",
        "\n",
        "for round_num in range(1, T + 1):\n",
        "    print(f\"\\n--- Round {round_num}/{T} ---\")\n",
        "    \n",
        "    global_herm = global_model.hermaphrodite.state_dict()\n",
        "    global_decoder = global_model.decoder.state_dict()\n",
        "    global_mu_c = global_model.mu_c.clone()\n",
        "    global_sigma_c = global_model.sigma_c.clone()\n",
        "    \n",
        "    delta_herm, delta_decoder, delta_mu_c, delta_sigma_c, n_k = client.local_train(\n",
        "        global_herm, global_decoder, global_mu_c, global_sigma_c\n",
        "    )\n",
        "    \n",
        "    for k in global_herm:\n",
        "        global_herm[k] += delta_herm[k]\n",
        "    for k in global_decoder:\n",
        "        global_decoder[k] += delta_decoder[k]\n",
        "    global_model.hermaphrodite.load_state_dict(global_herm)\n",
        "    global_model.decoder.load_state_dict(global_decoder)\n",
        "    global_model.mu_c += delta_mu_c\n",
        "    global_model.sigma_c += delta_sigma_c\n",
        "    \n",
        "    print(f\"Round {round_num} completed. Updated global model.\")\n",
        "\n",
        "print(\"\\nTraining Finished!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========================================\n",
            "Starting Evaluation...\n",
            "========================================\n",
            "\n",
            "\n",
            "Dataset: IoT-5\n",
            "Number of Clients: 6\n",
            "Number of Epochs: 5\n",
            "Number of Rounds: 10\n",
            "\n",
            "--- CTVAE Results ---\n",
            "Accuracy: 93.1\n",
            "F1-Score: 91.1\n",
            "\n",
            "--- F-CTVAE Results ---\n",
            "Accuracy: 94.45 (+1.35)\n",
            "F1-Score: 97.14 (+6.04)\n",
            "\n",
            "Confusion Matrix:\n",
            " [[    68  18579]\n",
            " [   780 329316]]\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"Starting Evaluation...\")\n",
        "print(\"=\"*40 + \"\\n\")\n",
        "\n",
        "def get_z_hat(model, X, y, batch_size=512):\n",
        "    model.eval()\n",
        "    z_hats = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(X), batch_size):\n",
        "            batch_x = X[i:i+batch_size].to(device)\n",
        "            batch_y = y[i:i+batch_size].to(device)\n",
        "            _, _, _, z_hat = model(batch_x, batch_y)\n",
        "            z_hats.append(z_hat.cpu().numpy())\n",
        "    return np.concatenate(z_hats)\n",
        "\n",
        "z_hat_train = get_z_hat(global_model, X_train, y_train)\n",
        "z_hat_test = get_z_hat(global_model, X_test, y_test)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=20, random_state=42, n_jobs=-1)\n",
        "rf.fit(z_hat_train, y_train.numpy())\n",
        "\n",
        "y_pred = rf.predict(z_hat_test)\n",
        "\n",
        "acc = accuracy_score(y_test.numpy(), y_pred) * 100\n",
        "# f1 = f1_score(y_test.numpy(), y_pred, average='macro') * 100\n",
        "f1 = f1_score(y_test, y_pred) * 100\n",
        "cm = confusion_matrix(y_test.numpy(), y_pred)\n",
        "\n",
        "# چاپ نتایج دقیقاً مثل مقاله\n",
        "print(f\"\\nDataset: IoT-{dataset_number}\")\n",
        "print(f\"Number of Clients: {K}\")\n",
        "print(f\"Number of Epochs: {local_epochs}\")\n",
        "print(f\"Number of Rounds: {T}\")\n",
        "\n",
        "print(\"\\n--- CTVAE Results ---\")\n",
        "print(f\"Accuracy: {get_ctvae_acc(dataset_number)}\")\n",
        "print(f\"F1-Score: {get_ctvae_f1(dataset_number)}\")\n",
        "\n",
        "print(\"\\n--- F-CTVAE Results ---\")\n",
        "print(f\"Accuracy: {acc:.2f} ({acc - get_ctvae_acc(dataset_number):+.2f})\")\n",
        "print(f\"F1-Score: {f1:.2f} ({f1 - get_ctvae_f1(dataset_number):+.2f})\")\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
